model_dir:                models/dummy
task:                     2
num_epochs:               50
batch_size:               16
restore_from_dir:         None
num_units:                256
num_enc_layers:           1
cell_type:                gru
learning_rate:            0.01
embedding_size:           256
val_split:                0.1
vocab:                    ../../../data/vocab.txt
dropout_keep_prob:        0.7
model_type:               normal
data_dir:                 ../../../data/en-10k
max_gradient_norm:        1.0
optimizer:                adam
encoder_type:             bi
merge_mode:               concat
Loading data...
vocabulary size = 487
Building model...
